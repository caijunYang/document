# 一、故障现象
	客户端开机后，部分用户投诉launcher界面一直转圈，无法加载布局。接口多次尝试出现无法响应情况。

# 二、故障处理路径


## 处理1
### 故障分析
	初判服务器处理能力不够
		解决方案：将tomcat从原来的2个实例（M1和M2分别一个），变成6个实例（M1和M2分别三个），并立即停掉迭代6的版本升级。
### 解决方案实施
	方案实施顺利，验证未出现问题。

## 高峰期仍报障，处理2
###   故障现象追加
	1、未响应现象为连接超时
###  故障分析
	1、	连接超时，为nginx处理能力达到设置上限。服务器及nginx处理能力较强，远未达到瓶颈，需要将nginx处理能力提高。
		解决方案:将nginx支撑连接数上调至2*10240
	2、查询资源占用，发现：
			mysql进程，cpu占用率过高；通过对流程和日志分析，发现每5分钟从数据库中更新主题数据到缓存中需要执行10分钟。初步判定，更新频率较高，且6个实例都在更新导致该情况出现。
			java进程cpu占用率过高；主题缓存更新堵塞，导致无法处理接收请求。
			日志中大量获取天气数据报错；报错均来自天气数据到redis获取失败，检查redis未发现异常。天气数据不影响该故障现象，暂搁置。
		解决方案：调整主题数据更新机制，提高更新时间；更新频率从原来的5分钟调整为30分钟，将tomcat实例从6个变成4个，并使用共享缓存+本地缓存的方式完成减少与数据库的直接交互。
	3、图片下载服务与数据接口公用，初判可能迭代六中图片资源较原来更多，下载连接数较多，进而影响数据接口请求。
		解决方案：采用独立端口为图片服务提供下载能力。
	4、恶意攻击判断。通过访问日志和网络包分析，发现负载均衡未透传客户端ip，无法给出结论，暂搁置。
	5、问题都出现在早6~早8和晚6~晚8点。初步判断因过节遇到用户访问高峰导致。
	6、通过以上一系列的问题，判断该问题非客户端问题，为用户使用高峰期平台测处理能力问题。
### 解决方案实施
	 1、nginx扩能实施顺利
	 2、tomcat实例调降后发现，天气请求数量较高，将减掉的两个实例改为承载独立天气服务后，发现天气连接数仍然较高，将天气数据改为静态文件。其余实施顺利，效果明显。
	 3、未通过该方案，未实施。
	整体方案实施完成后，验证未出现问题。

## 高峰期仍报障，处理3
### 故障再分析
	1、	M1和M2出现负载不均情况。初步怀疑是负载策略和会话保持共同作用，引起了该情况。
		通过与电信确认，发现确实采用的轮询负载，且会话保持为1200s。新建会话比例M1：M2=3：1。
		解决方案：将M1和M2的负载均衡中的会话保持取消，并将负载策略调整为最小化连接分配方式。
	2、 持续报错，通过对日志及nginx配置排查，发现已经从nginx中移除的服务，仍被继续负载。经多方核查nginx处理请求数较多reload未生效。
		解决方案：对nginx进行重启。
### 解决方案实施
		实施顺利，M1与M2会话逐步均匀化。
		由于客户对天气数据静态化影响业务，故再次将天气数据动态化恢复。

## 持续分析，发现异常，处理4
### 故障再分析
	1、通过对各服务的会话数分析，发现正常情况下天气会话数是其他会话数的好几倍，进而初步判定是天气接口请求异常。只能通过提高处理能力和响应速度来提高。
	解决方案：再次将天气数据静态化，将nginx进程数扩充至20。
### 解决方案实施
		实施顺利，未再见异常，M1与M2各服务稳定运行。

# 持续分析，找出触发以上问题原因
## 根源分析
	通过对客户端源码和流程分析，发现以下两种异常。
	1、每次推荐位跳转都会触发一次天气请求。
	2、客户端天气数据存在每天早8点和晚18点自动更新机制，且该采用广播通知的触发机制，导致实际请求量是业务需要的几十倍。
## 解决方案
	1、客户端尽快发布修复版本的apk。
    2、客户端版本未发布前，平台侧持续跟进。同时对现有部署进行调整。以保证业务数据获取稳定。
## 业务当前情况
	通过这几天的观察，连接图已由原来的陡增陡降变得平滑，且近期在最高点时，业务均未再见异常。已基本确定，可支撑到修复版本发布。

# 总结
   通过对该问题的修复，提升了平台对高并发业务的整理处理能力。为以后业务并发量需求达到6w时，平台端解决方案提供了实际案例参考及可实施性指导。
